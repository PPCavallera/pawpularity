{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petfinder-pawpularity-score.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c petfinder-pawpularity-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import walk\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import cv2\n",
    "import re\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import RandomSampler\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "TRAIN_PATH = './input/train'\n",
    "TEST_PATH = './input/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0007de18844b0dbbb5e1f607da0606e0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0009c66b9439883ba2750fb825e1d7db</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0013fd999caf9a3efe1352ca1b0d937e</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0018df346ac9c1d8413cfcc888ca8246</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001dc955e10590d3ca4673f034feeef2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbfa0383c34dc513c95560d6e1fdb57</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffcc8532d76436fc79e50eb2e5238e45</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffdf2e8673a1da6fb80342fa3b119a20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff19e2ce11718548fa1c5d039a5192a</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff8e47c766799c9e12f3cb3d66ad228</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9912 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "Id                                                                          \n",
       "0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "...                                         ...   ...   ...   ...     ...   \n",
       "ffbfa0383c34dc513c95560d6e1fdb57              0     0     0     1       0   \n",
       "ffcc8532d76436fc79e50eb2e5238e45              0     1     1     1       0   \n",
       "ffdf2e8673a1da6fb80342fa3b119a20              0     1     1     1       0   \n",
       "fff19e2ce11718548fa1c5d039a5192a              0     1     1     1       0   \n",
       "fff8e47c766799c9e12f3cb3d66ad228              0     1     1     1       0   \n",
       "\n",
       "                                  Accessory  Group  Collage  Human  Occlusion  \\\n",
       "Id                                                                              \n",
       "0007de18844b0dbbb5e1f607da0606e0          0      1        0      0          0   \n",
       "0009c66b9439883ba2750fb825e1d7db          0      0        0      0          0   \n",
       "0013fd999caf9a3efe1352ca1b0d937e          0      0        0      1          1   \n",
       "0018df346ac9c1d8413cfcc888ca8246          0      0        0      0          0   \n",
       "001dc955e10590d3ca4673f034feeef2          0      1        0      0          0   \n",
       "...                                     ...    ...      ...    ...        ...   \n",
       "ffbfa0383c34dc513c95560d6e1fdb57          0      0        0      0          0   \n",
       "ffcc8532d76436fc79e50eb2e5238e45          0      0        0      0          0   \n",
       "ffdf2e8673a1da6fb80342fa3b119a20          0      0        0      1          1   \n",
       "fff19e2ce11718548fa1c5d039a5192a          0      0        0      1          0   \n",
       "fff8e47c766799c9e12f3cb3d66ad228          0      0        0      0          0   \n",
       "\n",
       "                                  Info  Blur  Pawpularity  \n",
       "Id                                                         \n",
       "0007de18844b0dbbb5e1f607da0606e0     0     0           63  \n",
       "0009c66b9439883ba2750fb825e1d7db     0     0           42  \n",
       "0013fd999caf9a3efe1352ca1b0d937e     0     0           28  \n",
       "0018df346ac9c1d8413cfcc888ca8246     0     0           15  \n",
       "001dc955e10590d3ca4673f034feeef2     0     0           72  \n",
       "...                                ...   ...          ...  \n",
       "ffbfa0383c34dc513c95560d6e1fdb57     0     1           15  \n",
       "ffcc8532d76436fc79e50eb2e5238e45     0     0           70  \n",
       "ffdf2e8673a1da6fb80342fa3b119a20     0     0           20  \n",
       "fff19e2ce11718548fa1c5d039a5192a     0     0           20  \n",
       "fff8e47c766799c9e12f3cb3d66ad228     0     0           30  \n",
       "\n",
       "[9912 rows x 13 columns]"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_PATH+'.csv', index_col='Id')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for f in glob.iglob(TRAIN_PATH+'/*'):\n",
    "    images.append(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train =[]\n",
    "for i in images:\n",
    "    regexp_1 = re.compile(r'\\./input/[^/]*/(.*)\\..*')\n",
    "    re_match = regexp_1.match(i)\n",
    "    input_train.append((i,tuple(df_train[df_train.index == re_match.groups()[0]].iloc[0].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "     T.Resize((256,256)), \n",
    "     T.ToTensor(),\n",
    "     T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imgs_list, transforms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.imgs_list = imgs_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "    \n",
    "        image_path = self.imgs_list[index][0]\n",
    "        complentary_values = self.imgs_list[index][1][0:-1]\n",
    "        popularity = self.imgs_list[index][1][-1]\n",
    "        image = Image.open(image_path)\n",
    "        #Reading image\n",
    "        #Applying transforms on image\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, torch.tensor(list(complentary_values)).float(),popularity\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CompleteDataset(input_train, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    \n",
    "    print(train_dataset.__getitem__(i)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_random_sampler = RandomSampler(train_dataset)\n",
    "train_data_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = 16,\n",
    "    sampler = train_random_sampler,\n",
    "    num_workers = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1)\n",
    "\n",
    "        self.fc_cnn_1 = nn.Linear(16*254*254, 16)         \n",
    "        self.fc_linear_1 = nn.Linear(12,16)\n",
    "        self.fcout = nn.Linear(32, 1)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out_cnn = self.cnn1(x[0])\n",
    "        \n",
    "        out_cnn = out_cnn.view(out_cnn.size(0), -1)\n",
    "        out_cnn = self.fc_cnn_1(out_cnn)\n",
    "        out_linear = self.fc_linear_1(x[1])\n",
    "        out = torch.cat((out_cnn, out_linear), dim=1)\n",
    "        out = self.fcout(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc_cnn_1): Linear(in_features=1032256, out_features=16, bias=True)\n",
       "  (fc_linear_1): Linear(in_features=12, out_features=16, bias=True)\n",
       "  (fcout): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.75)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images,comp_values, labels) in enumerate(train_data_loader):\n",
    "\n",
    "    optimizer.zero_grad()        \n",
    "    preds = model([images, comp_values])\n",
    "    loss = criterion(preds, labels.float())\n",
    "    print(loss)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
